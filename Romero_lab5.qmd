---
title: "Guillermo Romero"
format: pdf
editor: visual
---

```{r}
library(spotifyr) #API interaction
library(tidyverse)
library(tidymodels)
library(readr)
library(skimr)
library(ggpubr)
library(patchwork)
library(caret)
library(corrplot)
library(flextable)
library(baguette)
library(ranger)
library(ggplot2)
library(vip)

```

# Data Wrangling

```{r}
Sys.setenv(SPOTIFY_CLIENT_ID = '22120fa7a3ee4f6dbb73fe9378000b6a')

Sys.setenv(SPOTIFY_CLIENT_SECRET = '32cf0124f63f4b9699c489ba57261666')
```

```{r}
access_token <-get_spotify_access_token(
  client_id ="22120fa7a3ee4f6dbb73fe9378000b6a",
  client_secret = "32cf0124f63f4b9699c489ba57261666" )
```

```{r}


get_all_tracks <- function(access_token, limit = 50, offset = 0, market = 'US') {
  tracks <- data.frame()
  
  repeat {
    response_data <- get_my_saved_tracks(limit = limit, offset = offset, market = market)
    tracks <- bind_rows(tracks,response_data)
    
    if (offset + limit >= 350) {
      break
    }
    offset <- offset + limit
  }
  
  tracks
}


```

```{r}
all_tracks <- get_all_tracks(access_token)
```

```{r}
feature1 <-  get_track_audio_features(all_tracks$track.id[1:100])
feature2 <- get_track_audio_features(all_tracks$track.id[101:200])
feature3 <- get_track_audio_features(all_tracks$track.id[201:300])
feature4 <- get_track_audio_features(all_tracks$track.id[301:328])

track_features <- bind_rows(feature1,feature2, feature3, feature4) |> 
  bind_cols(track_name = all_tracks$track.name)

#write_csv(track_features, 'track_features.csv')

```

```{r}
# 0 = Guillermo
#1 = Dalila
features_0 <- track_features |> 
  mutate(data_owned_by = as.factor(0)) |> 
  select(-type, -id,-uri,-track_href,-analysis_url) |>
  slice(1:200)


dalilas_tracks <- read.csv('dalila_spotify.csv') |> 
  mutate(data_owned_by = as.factor(1)) |> 
  select(-X,-type, -id,-uri,-track_href,-analysis_url)

tracks <- features_0 |> 
  bind_rows(dalilas_tracks)
```

# Data Exploration

```{r}
names(tracks)
skimr::skim(tracks)
```

### Top Ten

```{r}
# 0 = Guillermo
#1 = Dalila
danceability_top_ten <-  tracks |> 
  select(track_name, danceability, data_owned_by) |> 
  slice_max(n = 10,order_by = danceability)

energy_top_ten <- tracks |> 
  select(track_name, energy, data_owned_by) |> 
  slice_max(n = 10,order_by = energy)

valence_top_ten <- tracks |> 
  select(track_name, valence, data_owned_by) |> 
  slice_max(n = 10,order_by = valence)

instrument_top_ten <- tracks |> 
  select(track_name, instrumentalness, data_owned_by) |> 
  slice_max(n = 10,order_by = instrumentalness)
```

```{r}
# 0 = Guillermo
#1 = Dalila

danceability_10 <- danceability_top_ten  |> 
  gghistogram( x = "danceability", bins = 10,
   add = "mean", rug = TRUE,
   color = "data_owned_by", fill = "data_owned_by",
   palette = c("#0073C2FF", "#FC4E07"))+
  theme_pubclean()

energy_10 <- energy_top_ten  |> 
  gghistogram( x = "energy", bins = 10,
   add = "mean", rug = TRUE,
   color = "data_owned_by", fill = "data_owned_by",
   palette = c("#0073C2FF", "#FC4E07"))+
  theme_pubclean()

valence_10 <- valence_top_ten  |> 
  gghistogram( x = "valence", bins = 10,
   add = "mean", rug = TRUE,
   color = "data_owned_by", fill = "data_owned_by",
   palette = c("#0073C2FF", "#FC4E07"))+
  theme_pubclean()

instrument_10 <- instrument_top_ten  |> 
  gghistogram( x = "instrumentalness", bins = 10,
   add = "mean", rug = TRUE,
   color = "data_owned_by", fill = "data_owned_by",
   palette = c("#0073C2FF", "#FC4E07"))+
  theme_pubclean()

d10 <- flextable(danceability_top_ten)
e10 <- flextable(energy_top_ten)
v10 <- flextable(valence_top_ten)
i10 <- flextable(instrument_top_ten)
```

```{r}
((valence_10 + gen_grob(v10, fit = "width", just = "top", scaling = 'full')) 
/
(instrument_10 + gen_grob(i10, fit = "width", just = "top", scaling = 'full'))  )

((danceability_10 + gen_grob(d10, fit = 'width', just = "top", scaling = 'full')) /

(energy_10 + gen_grob(e10, fit = "width", just = "top", scaling = 'full')) )
```

### Danceability

```{r}
# overall distribution in danceability between two
danceability <- tracks  |> 
  gghistogram( x = "danceability", bins = 30,
   add = "mean", rug = TRUE,
   color = "data_owned_by", fill = "data_owned_by",
   palette = c("#0073C2FF", "#FC4E07"))+
  theme_pubclean()


  

danceabilty_valence <- tracks |> 
  ggplot(aes(x = valence, y = danceability, color = data_owned_by, size = energy)) +
  scale_size(range = c(0, 4)) +
  geom_count(alpha = 0.5) +
  labs(x= "Valence", y= "Danceability") +
  ggtitle("Valence vs. Danceability For Merged Datasets") +
  theme(plot.title = element_text(face="bold")) +
  theme(legend.position="bottom") +
  guides(col=guide_legend(ncol = 3)) +
  theme_pubr()


danceabilty_valence + danceability 

```

# KNN

```{r}
tracks_merged <- tracks |> 
  select(-track_name)

# Create training (70%) and test (30%) sets for the 
set.seed(123)  # for reproducibility (random sample)
spotify_split <- initial_split(tracks_merged, prop = 0.70)
spotify_train <- training(spotify_split)
spotify_test  <- testing(spotify_split)
spotify_split
```

```{r}
spotify_rec <- recipe(data_owned_by ~ ., data = spotify_train) |>
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |> 
  step_normalize(all_numeric(), -all_outcomes()) |> 
  prep() 
```

```{r}
knn_spec_tune <- nearest_neighbor(neighbors = tune())  |>  
  set_mode("classification") |> 
  set_engine("kknn")   
  
# Check the model
knn_spec_tune
```

```{r}
knn_fit <- knn_spec_tune %>% 
  fit(data_owned_by ~. , data = spotify_train)
```

```{r}
set.seed(123)
# 10-fold CV on the training dataset
cv_folds <- spotify_train |>  vfold_cv(v = 10)
```

```{r}
# Define our KNN model with tuning
# you can specify neigbors default five, can also put in tune() to tune
knn_spec_tune <- 
  nearest_neighbor(neighbors = tune()) |> 
  set_mode('classification') |> 
  set_engine('kknn')

# Check the model
knn_spec_tune
```

```{r}
# Define the workflow
wf_knn_tune <- 
    workflow() |> 
    add_model(knn_spec_tune) |> 
    add_recipe(spotify_rec)
```

```{r}
# Fit the workflow on our predefined folds and hyperparameters
fit_knn_cv <- wf_knn_tune |> 
  tune_grid(cv_folds,
            grid = data.frame(neighbors = c(1,5, seq(10, 100, 10))))
    
# Check the performance with collect_metrics()
fit_knn_cv|> collect_metrics()
```

```{r}
final_wf <- 
    wf_knn_tune |> 
    finalize_workflow(select_best(fit_knn_cv, metric = "accuracy"))
# Check out the final workflow object
final_wf
```

```{r}
# Fitting our final workflow
final_fit <- final_wf|> fit(data = spotify_train)
# Examine the final workflow
final_fit
```

```{r}
churn_pred <-  final_fit |> predict(new_data = spotify_test)

churn_pred |> head()
```

```{r}
# Write over 'final_fit' with this last_fit() approach
final_fit <-  final_wf |> last_fit(spotify_split)
# Collect metrics on the test data!
knn_perf <- final_fit|> collect_metrics()
```

# Decision Tree

```{r}
# Create training (70%) and test (30%) sets for the 
set.seed(123)  # for reproducibility (random sample)
spotify_split <- initial_split(tracks_merged, prop = 0.70)
spotify_train <- training(spotify_split)
spotify_test  <- testing(spotify_split)
spotify_split
```

```{r}
spotify_rec <- recipe(data_owned_by ~ ., data = spotify_train) |>
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  prep() 
```

```{r}
#new spec, tell the model that we are tuning hyperparams
tree_spec_tune <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()) |>
  set_engine('rpart') |>
  set_mode('classification')

tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)

tree_grid
```

```{r}
wf_tree_tune <- workflow() |> 
  add_recipe(spotify_rec) |> 
  add_model(tree_spec_tune) 
```

```{r}
#set up k-fold cv. This can be used for all the algorithms
decision_cv = spotify_train |> 
  vfold_cv(v=10) #10 standard default lower for computational resources
```

```{r}
doParallel::registerDoParallel() #build trees in parallel
#200s
tree_rs <- tune_grid(
  tree_spec_tune,
  #specification
  data_owned_by ~ .,
  # model function
  resamples = decision_cv,
  #resample specificaton
  grid = tree_grid,
  #parameters to try
  metrics = metric_set(accuracy) #asses which combination of parameters is best
)
tree_rs

```

```{r}
#Use autoplot() to examine how different parameter configurations relate to accuracy
autoplot(tree_rs) + theme_pubr()
```

```{r}
show_best <- show_best(tree_rs)
select_best <- select_best(tree_rs)

best <- flextable(show_best)
show <- flextable(select_best)

best  
show
```

```{r}
final_tree <- finalize_model(tree_spec_tune, 
                             select_best(tree_rs))
final_tree
```

```{r}
final_tree_fit <- last_fit(final_tree,
                           data_owned_by~.,
                           spotify_split)

predict <- as.data.frame(final_tree_fit$.predictions) |> select(-.config) |> head()

flextable(predict) |>  theme_zebra()
```

```{r}
tree_perf <- final_tree_fit %>%
  collect_metrics() %>%
  filter(.metric == "accuracy")
tree_perf
```

# Bagged Tree

```{r}
# Create training (70%) and test (30%) sets for the 
set.seed(123)  # for reproducibility (random sample)
spotify_split <- initial_split(tracks_merged, prop = 0.70)
spotify_train <- training(spotify_split)
spotify_test  <- testing(spotify_split)
spotify_split
```

```{r}
spotify_rec <- recipe(data_owned_by ~ ., data = spotify_train) |>
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |> 
  step_normalize(all_numeric(), -all_outcomes()) |> 
  prep() 
```

```{r}
bag_cv <- spotify_train %>% vfold_cv(v=5)

bag_spec_tune <- bag_tree(cost_complexity = tune(),
                          tree_depth = tune(),
                          min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("rpart", times = 50)

bag_grid <-
  grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)
bag_grid
```

```{r}
wf_bag_tune <- workflow() %>%
  add_recipe(spotify_rec) %>%
  add_model(bag_spec_tune)
wf_bag_tune
```

```{r}
doParallel::registerDoParallel() #build trees in parallel
bag_rs <- tune_grid(
  wf_bag_tune,
  data_owned_by ~.,
  resamples = bag_cv, #resamples to use
  grid = bag_grid,
  metrics = metric_set(accuracy))
```

```{r}
bag_rs |> collect_metrics()

```

```{r}
# get best model based on the metric
best_bag_mod <- select_best(bag_rs, "accuracy")

# fit the best model to the training data
final_bag <- finalize_workflow(wf_bag_tune, best_bag_mod) %>% 
  fit(data = spotify_train)
```

```{r}
# make predictions on the test set using the fitted model
test_pred <- final_bag %>% 
  predict(new_data = spotify_test) %>% 
  bind_cols(spotify_test)

# evaluate the accuracy of the fitted model on the test set
bag_perf <- test_pred %>% 
  metrics(truth = data_owned_by, estimate = .pred_class)
```

# Random Forest

```{r}
# Create training (70%) and test (30%) sets
set.seed(123)
spotify_split <- initial_split(tracks_merged, prop = 0.70)
spotify_train <- training(spotify_split)
spotify_test <- testing(spotify_split)

set.seed(234)
val_set <- validation_split(spotify_train, 
                            strata = data_owned_by, 
                            prop = 0.70)


# Create a recipe
spotify_rec <- recipe(data_owned_by ~ ., data = spotify_train) %>%
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  prep()
```

```{r}
# Create a Random Forest specification
rf_spec <-
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = 1000) %>%
  set_engine("ranger") %>%
  set_mode("classification")

# Create a Random Forest workflow
rf_workflow <- workflow() %>%
  add_recipe(spotify_rec) %>%
  add_model(rf_spec)
```

```{r}
set.seed(123)
doParallel::registerDoParallel()
set.seed(345)
rf_res <- 
  rf_workflow %>% 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(accuracy))
#> i Creating pre-processing data to finalize unknown parameter: mtry 
```

```{r}
rf_res |> collect_metrics()

```

```{r}
rf_res %>% 
  show_best(metric = "accuracy")
```

```{r}
autoplot(rf_res)
```

```{r}
# Get the best Random Forest model
best_rf <- select_best(rf_res, "accuracy")
best_rf
```

```{r}
rf_res %>% 
  collect_predictions()
```

```{r}
doParallel::registerDoParallel()

# the last model
last_rf_mod <- 
  rand_forest(mtry = 2, min_n = 3, trees = 1000) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("classification")

# the last workflow
last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

# the last fit
set.seed(345)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(spotify_split)

last_rf_fit
```

```{r}
rf_metrics <- last_rf_fit %>% 
  collect_metrics()
```

```{r}
last_rf_fit |> 
  extract_fit_parsnip() |> 
  vip::vip(num_features = 20) 
```

```{r}
rf_performance <- rf_metrics|> 
  select(performance = .estimate, .metric) |> 
  mutate(model = 'Random Forest') |> 
  slice(1:1)

tree_performance <- tree_perf |> 
  select(performance = .estimate, .metric) |> 
  mutate(model = 'Decision tree') |> 
  slice(1:1)

bag_performance <- bag_perf |> 
  select(performance = .estimate, .metric) |> 
  mutate(model = 'Bagged Tree') |> 
  slice(1:1)

knn_performance <- knn_perf |> 
  select(performance = .estimate, .metric) |> 
  mutate(model = 'KNN') |> 
  slice(1:1)

perfomance_metrics <- bind_rows(rf_performance,tree_performance, bag_performance, knn_performance) |> 
  mutate(model = as.factor(model))


flextable(perfomance_metrics) |>  theme_booktabs()
```

```{r}
ggplot(perfomance_metrics, aes(x = model, y = performance)) +
  geom_col()+ theme_pubr()
```
