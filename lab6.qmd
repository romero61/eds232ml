---
title: "Lab6"
author: {Student Name}
date: "2023-03-01"
output: html_document
---

## Case Study Eel Species Distribution Modeling

This week's lab follows a modeling project described by Elith et al. (2008) (Supplementary Reading)

## Data

Grab the model training data set from the class Git:

data/eel.model.data.csv

### Split and Resample

Split the joined data from above into a training and test set, stratified by outcome score. Use 10-fold CV to resample the training set, stratified by Angaus

### Preprocess

Create a recipe to prepare your data for the XGBoost model. We are interested in predicting the binary outcome variable Angaus which indicates presence or absence of the eel species Anguilla australis

## Tuning XGBoost

### Tune Learning Rate

Following the XGBoost tuning strategy outlined on Monday, first we conduct tuning on just the learn_rate parameter:

1.  Create a model specification using {xgboost} for the estimation

-   Only specify one parameter to tune()

2.  Set up a grid to tune your model by using a range of learning rate parameter values: expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))

-   Use appropriate metrics argument(s) - Computational efficiency becomes a factor as models get more complex and data get larger. Record the time it takes to run. Do this for each tuning phase you run.You could use {tictoc} or Sys.time().

3.  Show the performance of the best models and the estimates for the learning rate parameter values associated with each.

### Tune Tree Parameters

1.  Create a new specification where you set the learning rate (which you already optimized) and tune the tree parameters.

2.  Set up a tuning grid. This time use grid_max_entropy() to get a representative sampling of the parameter space

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.

### Tune Stochastic Parameters

1.  Create a new specification where you set the learning rate and tree parameters (which you already optimized) and tune the stochastic parameters.

2.  Set up a tuning grid. Use grid_max_entropy() again.

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.

## Finalize workflow and make final prediction

1.  Assemble your final workflow will all of your optimized parameters and do a final fit.

2.  How well did your model perform? What types of errors did it make?

## Fit your model the evaluation data and compare performance

1.  Now fit your final model to the big dataset: data/eval.data.csv

2.  How does your model perform on this data?

3.  How do your results compare to those of Elith et al.?

-   Use {vip} to compare variable importance
-   What do your variable importance results tell you about the distribution of this eel species?
